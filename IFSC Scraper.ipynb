{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa1373f-a803-4146-b30b-12291b14fd46",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "## Import Libraries & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f437b8d-efdc-4953-902f-6efb6160713f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17bc8-1883-4d02-b297-ad9abb029de3",
   "metadata": {},
   "source": [
    "## Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92492156-0021-4d11-b87a-2ad2f2e193cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\n",
    "    os.path.dirname(os.path.realpath(\"__file__\")), \"data\"\n",
    ")\n",
    "\n",
    "BOULDER_MEN_DIR            = os.path.join(DATA_DIR, \"Boulder/Men\")\n",
    "BOULDER_WOMEN_DIR          = os.path.join(DATA_DIR, \"Boulder/Women\")\n",
    "LEAD_MEN_DIR               = os.path.join(DATA_DIR, \"Lead/Men\")\n",
    "LEAD_WOMEN_DIR             = os.path.join(DATA_DIR, \"Lead/Women\")\n",
    "SPEED_MEN_DIR              = os.path.join(DATA_DIR, \"Speed/Men\")\n",
    "SPEED_WOMEN_DIR            = os.path.join(DATA_DIR, \"Speed/Women\")\n",
    "COMBINED_MEN_DIR           = os.path.join(DATA_DIR, \"Combined/Men\")\n",
    "COMBINED_WOMEN_DIR         = os.path.join(DATA_DIR, \"Combined/Women\")\n",
    "BOULDER_AND_LEAD_MEN_DIR   = os.path.join(DATA_DIR, \"Boulder & Lead/Men\")\n",
    "BOULDER_AND_LEAD_WOMEN_DIR = os.path.join(DATA_DIR, \"Boulder & Lead/Women\")\n",
    "\n",
    "dirs = [BOULDER_MEN_DIR, BOULDER_WOMEN_DIR, LEAD_MEN_DIR, LEAD_WOMEN_DIR,\n",
    "       SPEED_MEN_DIR, SPEED_WOMEN_DIR, COMBINED_MEN_DIR, COMBINED_WOMEN_DIR,\n",
    "       BOULDER_AND_LEAD_MEN_DIR, BOULDER_AND_LEAD_WOMEN_DIR]\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "# File to store names of events that have already been scraped\n",
    "try:\n",
    "    ALREADY_SCRAPED = os.path.join(DATA_DIR, \"scraped_events.txt\")\n",
    "    # Create file\n",
    "    with open(ALREADY_SCRAPED, 'x') as fp:\n",
    "        pass\n",
    "except:\n",
    "    if os.stat(ALREADY_SCRAPED).st_size == 0:\n",
    "        print(\"No data has been scraped yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2d3c4-a7e4-4804-87c2-8ed71e1df696",
   "metadata": {},
   "source": [
    "## IFSCScraper Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b766d9d-36c2-41b9-acb0-7a413519ba06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IFSCScraper():\n",
    "    \"\"\"\n",
    "    Define a class for the scraper that will be used to gather data from the IFSC website\n",
    "    (ifsc-climbing.org). Includes methods that allow for scraping different pages and \n",
    "    different information.\n",
    "    \"\"\"\n",
    "    # Page url\n",
    "    url  = 'https://ifsc.results.info'\n",
    "    url2 = 'https://ifsc.results.info/#/athlete/'\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a scraper object with its own browser instance.\n",
    "        \n",
    "        debug: indicates whether this is a debug instance for quicker development\n",
    "        \"\"\"\n",
    "        self.generate_driver()\n",
    "        time.sleep(10)\n",
    "    \n",
    "    def generate_driver(self):\n",
    "        \"\"\"\n",
    "        Initialize Selenium web browser.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Sets headless option, so we don't see browser\n",
    "            headOption = webdriver.FirefoxOptions()\n",
    "            headOption.add_argument(\"--headless\")\n",
    "            self.driver = webdriver.Firefox(options=headOption)\n",
    "            wait = WebDriverWait(self.driver, 10)\n",
    "        except Exception as ex:\n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            print(message)\n",
    "        \n",
    "    def load_page(self, link, athlete_page=0, timeout=10, wait_after=1):\n",
    "        \"\"\"\n",
    "        Helper function that opens browser, loads a page, and waits for timeout.\n",
    "        \n",
    "        link: link to the page we wish to load\n",
    "        athlete_page: flag to load different url\n",
    "        timeout: seconds to wait before timing out\n",
    "        wait_after: seconds to wait after loading\n",
    "        \"\"\"\n",
    "\n",
    "        # Visit link\n",
    "        self.driver.get(link)\n",
    "        wait = WebDriverWait(self.driver, timeout)\n",
    "\n",
    "        # Attempt to open link\n",
    "        try:\n",
    "            if athlete_page:\n",
    "                wait.until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='athlete-info left-side']\")))\n",
    "            else:\n",
    "                wait.until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='uk-container']\")))\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for page \" + link + \" to load\")\n",
    "            self.driver.quit()\n",
    "\n",
    "        # Wait for page to load\n",
    "        time.sleep(wait_after)\n",
    "    \n",
    "    def get_year_list(self):\n",
    "        \"\"\"\n",
    "        Opens browser and gets list of all years listed on IFSC website.\n",
    "        \n",
    "        Returns list of years (as strings)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)            \n",
    "            wait = WebDriverWait(self.driver, 10)\n",
    "            \n",
    "            # The data we are after resides within an iframe\n",
    "            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe.jch-lazyloaded\")))\n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "        year_opts = Select(year_dd).options\n",
    "        return [year.text for year in year_opts]\n",
    "    \n",
    "    def get_single_year(self, year='2022'):\n",
    "        \"\"\"\n",
    "        Fully scrape each event and category for a given year.\n",
    "        \n",
    "        year: string of the year you want to scrape\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url)            \n",
    "            wait = WebDriverWait(self.driver, 8)\n",
    "            \n",
    "            # The data we are after resides within an iframe\n",
    "            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe.jch-lazyloaded\")))\n",
    "            print(f'Scraping {year}...')\n",
    "        except:\n",
    "            print('Error loading page!')        \n",
    "        \n",
    "        # Dropdown menus for each choice\n",
    "        year_dd, league_dd, event_dd, cat_dd = self.get_dropdowns(self.driver)\n",
    "        \n",
    "        # Select given year and league\n",
    "        year_ob   = Select(year_dd).select_by_visible_text(year)\n",
    "        league_ob = Select(league_dd).select_by_index(1)\n",
    "        \n",
    "        # Get list of all events for the year\n",
    "        all_events = self.get_events(self.driver, event_dd)\n",
    "        \n",
    "        # Loop through each event, scrape results, and generate .csv file\n",
    "        dfs = []\n",
    "        for i, event in enumerate(all_events):\n",
    "            # Implement check to see if event has already been scraped\n",
    "            if self.check_if_scraped(event) and all_events[i] != all_events[i-1]:\n",
    "                print(f'--Already scraped {event}!')\n",
    "                continue\n",
    "            # Some of the events aren't actually events, but more qualification rounds, and \n",
    "            # they don't list the results correctly, which will cause errors. The common thread\n",
    "            # is the naming of them.\n",
    "            elif event.count('(') < 1:\n",
    "                print(f'--Skipping {event}...')\n",
    "                continue\n",
    "            else:\n",
    "                # Set this flag for special cases where two events share the same name (rare)\n",
    "                same_event_name = True if all_events[i] == all_events[i-1] else False\n",
    "                                    \n",
    "                # Select event\n",
    "                if same_event_name:\n",
    "                    event_ob = Select(event_dd).select_by_index(i+1)                    \n",
    "                else:\n",
    "                    event_ob = Select(event_dd).select_by_visible_text(event)\n",
    "                    \n",
    "                category_select = Select(cat_dd)\n",
    "\n",
    "                # Some events were cancelled or don't have results listed, check for it here\n",
    "                try:\n",
    "                    wait.until(lambda d: len(category_select.options) > 1)\n",
    "                    if not self.check_if_scraped(event):\n",
    "                        # self.add_to_scraped_file(event)\n",
    "                        print(f'--Scraping {event}...')\n",
    "                except:\n",
    "                    print(f'--No data for {event}!')\n",
    "                    continue\n",
    "\n",
    "                # Get results for each category\n",
    "                for cat in category_select.options[1:]:\n",
    "                    cat_ob = Select(cat_dd).select_by_visible_text(cat.text) # selects category\n",
    "\n",
    "                    # Finds table with desired data\n",
    "                    try:\n",
    "                        wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@id=\"table_id_wrapper\"]')))\n",
    "                    except:\n",
    "                        print(f'----No data for {cat.text}!')\n",
    "                        continue\n",
    "\n",
    "                    table_wrapper = self.driver.find_element(By.XPATH, '//div[@id=\"table_id_wrapper\"]')\n",
    "                    results = table_wrapper.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "                    # Get event name and date\n",
    "                    event_details = self.driver.find_element(By.XPATH, '//div[@class=\"labels\"]')\n",
    "                    event_results = event_details.find_elements(By.TAG_NAME, 'p') # Event title & date\n",
    "\n",
    "                    # Sets event name in case of duplicate\n",
    "                    if same_event_name:\n",
    "                        event = event[:-10] + '2 ' + event[-10:]\n",
    "                        same_event_name = False\n",
    "                    \n",
    "                    # Generate correct filename\n",
    "                    file = self.generate_filename((cat.text, event_results[0].text, event_results[1].text))\n",
    "                    text = '--' + file\n",
    "                    path = self.get_dir(cat.text)                    \n",
    "                    filepath = os.path.join(path, file)\n",
    "                                        \n",
    "                    # Checks if the filename has been added to the .txt, AND if the file exists\n",
    "                    if self.check_if_scraped(text, filepath):\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f'----Scraping {cat.text}...')\n",
    "                        \n",
    "                        # Data (list of dictionaries) contains each climber's results\n",
    "                        data = []\n",
    "                        for result in results:\n",
    "                            # Each climber's result stored in dict\n",
    "                            temp_dict = self.scrape_results(event, result, cat.text)\n",
    "                            \n",
    "                            if temp_dict:\n",
    "                                data.append(temp_dict)\n",
    "                            else:\n",
    "                                print(f'----Data format error for {cat.text}! Cannot parse it further. Skipping...')\n",
    "                                break\n",
    "                        \n",
    "                        if data:\n",
    "                            # Convert raw results into a .csv and marks file as scraped\n",
    "                            df = pd.DataFrame.from_dict(data)                            \n",
    "                            self.convert_to_csv(file, cat.text, df)\n",
    "                            self.add_to_scraped_file('--' + file)\n",
    "                        \n",
    "                # All categories for the event have been scraped\n",
    "                self.add_to_scraped_file(event)\n",
    "                        \n",
    "    def get_athlete_height(self, athlete_id):\n",
    "        \"\"\"\n",
    "        Scrape athlete page for climber's height\n",
    "        \n",
    "        athlete_id: unique id assigned to each climber\n",
    "        Returns height of given climber\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_page(IFSCScraper.url2 + athlete_id, athlete_page=1)            \n",
    "        except:\n",
    "            print('Error loading page!')\n",
    "            self.driver.quit()\n",
    "        \n",
    "        height_div = self.driver.find_element(By.XPATH, '//div[@class=\"athlete-info left-side\"]')\n",
    "        height_ele = height_div.find_elements(By.TAG_NAME, 'div')[1]\n",
    "        return height_ele.text.split(': ')[1]\n",
    "    \n",
    "    def add_to_scraped_file(self, text):\n",
    "        \"\"\"\n",
    "        Adds given text to our tracker file to keep track of what has been scraped.\n",
    "        \n",
    "        text: string of text to add to file\n",
    "        \"\"\"\n",
    "        if not self.check_if_scraped(text):\n",
    "            with open(ALREADY_SCRAPED, 'a') as file:\n",
    "                file.write(f'{text}\\n')\n",
    "                return\n",
    "    \n",
    "    def check_if_scraped(self, text, file = ''):\n",
    "        \"\"\"\n",
    "        Checks if the given text exists in the given file.\n",
    "        \n",
    "        text: string of text to check in file\n",
    "        file: name of file to check for existence\n",
    "        Returns true/false\n",
    "        \"\"\"\n",
    "        with open(ALREADY_SCRAPED, 'r') as f:\n",
    "            done = [x.strip() for x in f.readlines()]\n",
    "            \n",
    "        if file:\n",
    "            if text in done and os.path.exists(file):\n",
    "                return True\n",
    "            return False\n",
    "        return text in done\n",
    "\n",
    "    def scrape_results(self, event, result, cat):\n",
    "        \"\"\"\n",
    "        Function to scrape the desired results from a given event and category.\n",
    "        \n",
    "        event: name of event to scrape\n",
    "        result: individual climber's results for given event\n",
    "        cat: category (men's or women's)\n",
    "        Returns dictionary with correct result format based on category\n",
    "        \"\"\"\n",
    "        details = result.find_elements(By.TAG_NAME, 'td')\n",
    "        athlete_id = details[1].find_element(By.TAG_NAME, 'a').get_attribute('href').split('id=')[1]\n",
    "\n",
    "        if \"LEAD\" in cat or \"BOULDER\" in cat:\n",
    "            try:                \n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Gender\": 'F' if 'WOMEN' in cat.upper() else 'M',\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text,\n",
    "                    \"Semi-Final\": details[5].text\n",
    "                }\n",
    "                if len(details) == 7: #each round has data\n",
    "                    temp_dict[\"Final\"] = details[6].text\n",
    "                else: # semi-final round acts as final\n",
    "                    temp_dict[\"Final\"] = details[5].text\n",
    "                \n",
    "            except:\n",
    "                return False\n",
    "        elif \"SPEED\" in cat:\n",
    "            try:\n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Gender\": 'F' if 'WOMEN' in cat.upper() else 'M',\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text,\n",
    "                    \"Final\": details[5].text\n",
    "                }\n",
    "            except:\n",
    "                return False\n",
    "        else:\n",
    "            try:\n",
    "                temp_dict = {\n",
    "                    \"Event\": event,\n",
    "                    \"ID\": athlete_id,\n",
    "                    \"Rank\": details[0].text,\n",
    "                    \"Name\": f\"{details[1].text} {details[2].text}\",\n",
    "                    \"Gender\": 'F' if 'WOMEN' in cat.upper() else 'M',\n",
    "                    \"Country\": details[3].text,\n",
    "                    \"Qualification\": details[4].text\n",
    "                }\n",
    "            except:\n",
    "                return False\n",
    "        return temp_dict\n",
    "    \n",
    "    def get_dropdowns(self, driver):\n",
    "        \"\"\"\n",
    "        Helper function to quickly find the four dropdown menus on the page.\n",
    "        \n",
    "        driver: selenium web driver\n",
    "        Returns one web element for each dropdown menu\n",
    "        \"\"\"\n",
    "        year_dd   = driver.find_element(By.XPATH, '//select[@id=\"years\"]')\n",
    "        league_dd = driver.find_element(By.XPATH, '//select[@id=\"indexes\"]')\n",
    "        event_dd  = driver.find_element(By.XPATH, '//select[@id=\"events\"]')\n",
    "        cat_dd    = driver.find_element(By.XPATH, '//select[@id=\"categories\"]')        \n",
    "        return year_dd, league_dd, event_dd, cat_dd\n",
    "    \n",
    "    def get_events(self, driver, events_dd):\n",
    "        \"\"\"\n",
    "        Function to get a list of all events.\n",
    "        \n",
    "        driver: selenium web element\n",
    "        events_dd: dropdown element for the event menu\n",
    "        Returns list of events in the events_dd menu\n",
    "        \"\"\"\n",
    "        event_opts = Select(events_dd)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(lambda d: len(event_opts.options) > 1)                    \n",
    "        return [x.text for x in event_opts.options[1:]]\n",
    "    \n",
    "    def generate_filename(self, packed_data):\n",
    "        \"\"\"\n",
    "        Function to take the event name and convert it to a consistent, formatted filename.\n",
    "        \n",
    "        packed_data: tuple containing all necessary info to generate the filename\n",
    "        \"\"\"\n",
    "        # Unpacks data\n",
    "        (category, event, date) = packed_data\n",
    "\n",
    "        # Create filename in form of {date}_{event}_{category}\n",
    "        date = ' '.join(date.split()[::-1][:3])       \n",
    "\n",
    "        # Cleans up event name for next part\n",
    "        event = event.replace('- ', '').split()\n",
    "        if event[-1] == 'CANCELLED':\n",
    "            event = ' '.join(event[:-2])\n",
    "        else:\n",
    "            event = ' '.join(event[:-1])\n",
    "\n",
    "        # Uses Regex to clean because not every name has the same format\n",
    "        filename = ' '.join([date, event, category])\n",
    "        filename = re.findall(\"^[^\\(]+|[\\(].*\", filename)\n",
    "        filename[1] = filename[1].split(') ', 1)[1]\n",
    "        filename = (''.join(filename)\n",
    "                    .replace('(','[')\n",
    "                    .replace(')',']')\n",
    "                    .replace(' ', '_')\n",
    "                    .replace(',', '')\n",
    "                    .lower()) + '.csv'        \n",
    "        return filename\n",
    "\n",
    "    def convert_to_csv(self, filename, category, data):\n",
    "        \"\"\"\n",
    "        Function to take the given data and create a .csv with the given filename\n",
    "        in the given category directory.\n",
    "        \n",
    "        filename: filename generated by generate_filename function\n",
    "        category: men's or women's (used to differentiate directory)\n",
    "        data: dataframe we want to save\n",
    "        \"\"\"\n",
    "        # Figure out correct directory\n",
    "        path = self.get_dir(category)\n",
    "        file = path + f'\\\\{filename}'\n",
    "\n",
    "        # Generates .csv with filename\n",
    "        data.to_csv(file, index=False)\n",
    "            \n",
    "    def get_dir(self, category):\n",
    "        \"\"\"\n",
    "        Function to return the proper directory to use, based on category.\n",
    "        \n",
    "        category: men's or women's\n",
    "        \"\"\"\n",
    "        base = category.upper().split()\n",
    "        if \"MEN\" in base:\n",
    "            if \"BOULDER\" in base: return BOULDER_MEN_DIR\n",
    "            if \"LEAD\" in base: return LEAD_MEN_DIR\n",
    "            if \"SPEED\" in base: return SPEED_MEN_DIR\n",
    "            if \"COMBINED\" in base: return COMBINED_MEN_DIR\n",
    "            if \"BOULDER&LEAD\" in base: return BOULDER_AND_LEAD_MEN_DIR\n",
    "        if \"WOMEN\" in base:\n",
    "            if \"BOULDER\" in base: return BOULDER_WOMEN_DIR\n",
    "            if \"LEAD\" in base: return LEAD_WOMEN_DIR\n",
    "            if \"SPEED\" in base: return SPEED_WOMEN_DIR\n",
    "            if \"COMBINED\" in base: return COMBINED_WOMEN_DIR\n",
    "            if \"BOULDER&LEAD\" in base: return BOULDER_AND_LEAD_WOMEN_DIR\n",
    "                \n",
    "    def end_session(self):\n",
    "        \"\"\"Basic function to end the selenium web driver and close the browser.\"\"\"\n",
    "        print('SESSION DONE! Quitting webdriver and closing browser...')\n",
    "        self.driver.quit()\n",
    "        \n",
    "    def scrape_all_ifsc_world_cups(self):\n",
    "        \"\"\"\n",
    "        Complete function to go through each year and scrape all IFSC World Cup\n",
    "        competitions. Currently does not include 2023 because those events have\n",
    "        not happened yet.\n",
    "        \"\"\"\n",
    "        years = self.get_year_list()\n",
    "        for year in years[:-17]: # 2023-2007, 2023 events ongoing\n",
    "            scraper.get_single_year(year)\n",
    "        self.end_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e6fe95-2e7a-4fa5-9093-6f2d6fab89ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out waiting for page https://ifsc.results.info to load\n",
      "Error loading page!\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=54209): Max retries exceeded with url: /session/749a1e5a-409c-46e9-ab7e-115b12784fc2/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe8d0c7e130>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fe8d0c7e130>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m scraper \u001b[38;5;241m=\u001b[39m IFSCScraper()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# scraper.scrape_all_ifsc_world_cups() # Run once to gather everything\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m scraper\u001b[38;5;241m.\u001b[39mget_single_year(\u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_year_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# Gets results for most recent year\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scraper\u001b[38;5;241m.\u001b[39mend_session()\n",
      "Cell \u001b[0;32mIn[8], line 78\u001b[0m, in \u001b[0;36mIFSCScraper.get_year_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError loading page!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Dropdown menus for each choice\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m year_dd, league_dd, event_dd, cat_dd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dropdowns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m year_opts \u001b[38;5;241m=\u001b[39m Select(year_dd)\u001b[38;5;241m.\u001b[39moptions\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [year\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m year_opts]\n",
      "Cell \u001b[0;32mIn[8], line 311\u001b[0m, in \u001b[0;36mIFSCScraper.get_dropdowns\u001b[0;34m(self, driver)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dropdowns\u001b[39m(\u001b[38;5;28mself\u001b[39m, driver):\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    Helper function to quickly find the four dropdown menus on the page.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    driver: selenium web driver\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Returns one web element for each dropdown menu\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     year_dd   \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//select[@id=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myears\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     league_dd \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//select[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    313\u001b[0m     event_dd  \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//select[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:914\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:445\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    443\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 445\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    136\u001b[0m         method,\n\u001b[1;32m    137\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    870\u001b[0m     )\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    870\u001b[0m     )\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    870\u001b[0m     )\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[0;32m/jukebox/scratch/bichanw/miniconda3/envs/neu502b/lib/python3.9/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=54209): Max retries exceeded with url: /session/749a1e5a-409c-46e9-ab7e-115b12784fc2/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe8d0c7e130>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# Takes ~37 minutes to scrape all years and events\n",
    "scraper = IFSCScraper()\n",
    "# scraper.scrape_all_ifsc_world_cups() # Run once to gather everything\n",
    "scraper.get_single_year(scraper.get_year_list()[0]) # Gets results for most recent year\n",
    "scraper.end_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3121a-24da-477b-86e8-e5d23abb99ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
